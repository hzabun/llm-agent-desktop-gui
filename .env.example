# LLM Backend Configuration
# Choose between "openai" or "llama-cpp"
LLM_BACKEND=openai

# OpenAI API Configuration (if using LLM_BACKEND=openai)
OPENAI_API_KEY=your-api-key-here

# Notes:
# - For local LLM: Set LLM_BACKEND=llama-cpp and install llama-cpp-python with GPU support
# - For OpenAI API: Keep LLM_BACKEND=openai (default) and set your API key above
# - See README.md for detailed setup instructions
